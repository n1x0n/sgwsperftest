#!/usr/bin/env python

from __future__ import print_function

"""
This script takes a bucket and downloads all objects
from StorageGRID Webscale.
"""

############################################################
# Modules
############################################################
import time
import socket
import sys
import os
from contextlib import closing
import json
import boto3
import boto3.session
import requests
import configparser
import multiprocessing as mp
import re
import random
from subprocess import Popen, PIPE, STDOUT


############################################################
# Global Variables
############################################################
timer_start = time.time()
download_start = time.time()
test_start = time.time()
counter = 0
totalsize = 0
certfile = ""
resultlist = []
threshold = 0.5
longesttime = 0


############################################################
# Helper Functions
############################################################
def usage():
    print("Usage: download_data.py CONFIGFILE")


def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)


def debug(message):
    """Prints debug messages.."""
    DEBUG=False
    if "DEBUG" in os.environ:
        if os.environ["DEBUG"] == "0":
            DEBUG=False
        else:
            DEBUG=True
    if not DEBUG:
        return
    now = time.time()
    elapsed = now - timer_start
    eprint("[%f] %s" % (elapsed, message))
    return


def abort(message="Unknown error"):
    """Aborts with message."""
    now = time.time()
    elapsed = now - timer_start
    eprint("[%f] ABORT: %s" % (elapsed, message))
    quit(1)


def quit(exitcode=0):
    cleanup()
    debug("Exiting with code %s." % exitcode)
    sys.exit(exitcode)


def cleanup():
    """Called once in quit/abort, used to cleanup."""
    debug("Cleaning up")
    return True


############################################################
# Functions
############################################################
def get_options(config):
    if not (len(sys.argv) > 1):
        usage()
        quit(1)

    try:
        config.read(sys.argv[1])
    except Exception as e:
        abort("Error when reading configuration: %s" % e.message)


def download(url):
    # This function downloads 1 url and returns performance data.
    retval = ""
    start = time.time()

    with Popen(["/usr/bin/curl", "-s", "--insecure", "-w", "%{time_namelookup};%{time_connect};%{time_appconnect};%{time_pretransfer};%{time_redirect};%{time_starttransfer};%{time_total};%{size_download};%{speed_download};%{url_effective}", "-o", "/dev/null", ("%s" % url)], stdout=PIPE) as p:
        retval = p.stdout.readline().decode()

    end = time.time()

    return("%s;%s;%s" % (retval, start, end))


def collect_result(result):
    global resultlist
    global download_start
    global counter
    global totalsize
    global longesttime
    data = result.split(";")
    resultlist.append(data)
    size = int(data[7])
    if ( float(data[5]) > threshold ):
        longesttime += 1
    counter += 1
    totalsize += size
    if not ( counter % 100 ):
        now = time.time()
        elapsed = now - download_start
        objs_per_sec = "%.0f" % (counter / elapsed)
        megabytes_per_sec = "%.2f" % (totalsize / elapsed / 1024 / 1024)
        print("%s files downloaded in %.1f secs. %s objects/s, %s MB/s, %s above %s sec" % (counter, elapsed, objs_per_sec, megabytes_per_sec, longesttime, threshold))


def main():
    """Main entrypoint for the script"""

    config = configparser.ConfigParser()
    get_options(config)

    baseurl = "%s://%s:%s" % (
        config['perftest']['protocol'],
        config['perftest']['endpoints'].split(",")[0],
        config['perftest']['port'],
	)

    global certfile
    certfile = config['perftest']['certfile']

    print("Downloading from: %s" % config['perftest']['bucketname'])
    print("Storage nodes: %s" % config['perftest']['endpoints'])

    workers = int(config['perftest']['workers'])

    # We need to pass everything that boto3 needs into
    # each sub process.
    session = boto3.session.Session(aws_access_key_id=config['perftest']['access_key'], aws_secret_access_key=config['perftest']['secret_key'])
    s3 = ""
    if config['perftest']['protocol'] == "https":
        s3 = session.resource(service_name='s3', endpoint_url=baseurl, verify=config['perftest']['certfile'])
    else:
        s3 = session.resource(service_name='s3', endpoint_url=baseurl)

    bucket = s3.Bucket(config['perftest']['bucketname'])

    print("Getting list of objects.")
    working_policies = True
    policy = {
      "Statement":[
            {
                "Sid":"AddPerm",
                "Effect":"Allow",
                "Principal": "*",
                "Action":["s3:ListBucket"],
                "Resource":["urn:sgws:s3:::" + config['perftest']['bucketname']]
            },
        {
          "Sid":"AddPerm",
          "Effect":"Allow",
          "Principal": "*",
          "Action":["s3:GetObject"],
          "Resource":["urn:sgws:s3:::" + config['perftest']['bucketname'] + "/*"]
        }
      ]
    }

    try: 
        bucket.Policy().put(Policy=json.dumps(policy))
    except:
        working_policies = False


    work = []
    num_endpoints = len(config['perftest']['endpoints'].split(","))

    # The previous version of this script downloaded a list of keys
    # from the bucket. This was time consuming so instead we reuse
    # a text file listing all the keys. I keep the old code here for
    # reference.
    # for thisfile in bucket.objects.all():
    #     if not working_policies:
    #         thisfile.Acl().put(ACL="public-read")
    #     thisurl = "%s://%s:%s" % (
    #         config['perftest']['protocol'],
    #         config['perftest']['endpoints'].split(",")[(len(work) % num_endpoints)],
    #         config['perftest']['port'],
    #     )
    #     dummy = ["%s/%s/%s" % (thisurl, config['perftest']['bucketname'], thisfile.key)]
    #     work.append(dummy)


    with open(config['perftest']['filelist'], "r") as filelist:
        for line in filelist:
            line = line.rstrip()
            thisurl = "%s://%s:%s" % (
                config['perftest']['protocol'],
                config['perftest']['endpoints'].split(",")[(len(work) % num_endpoints)],
                config['perftest']['port'],
            )
            dummy = ["%s/%s/%s" % (thisurl, config['perftest']['bucketname'], line)]
            work.append(dummy)

    filelist.close

    print("Found %s objects." % len(work))
    print("Shuffling list to randomize download pattern.")
    random.shuffle(work)

    numobjs =  int(config['perftest']['number_of_objects']) 
    work = work[0:numobjs]
    print("Downloading %s objects." % len(work))
    print("Starting download.")

    pool = mp.Pool(processes=workers)
    global download_start
    download_start = time.time()
    for key in work:
        pool.apply_async(download, key, callback=collect_result)
    pool.close()
    pool.join()

    global counter
    global totalsize

    now = time.time()
    elapsed = now - download_start
    objs_per_sec = "%.0f" % (counter / elapsed)
    megabytes_per_sec = "%.2f" % (totalsize / elapsed / 1024 / 1024)
    print("SUMMARY: %s files downloaded in %.1f secs. %s objects/s, %s MB/s" % (counter, elapsed, objs_per_sec, megabytes_per_sec))

    test_end = time.time()


    f = open("/tmp/histodata", "w")
    global resultlist
    f.write("time_namelookup,time_connect,time_appconnect,time_pretransfer,time_redirect,time_starttransfer,time_total,size_download,speed_download,url_effective,start_time,end_time\n")
    for data in resultlist:
        #data[10] = str(float(data[10]) - download_start);
        #data[11] = str(float(data[11]) - download_start);
        string = ",".join(data)
        f.write("%s\n" % string)
    f.close


    # Upload the bucket to S3 storage for parsing.
    bucket = ""
    try:
        bucket = s3.create_bucket(Bucket=config['perftest']['upload_bucket'])
    except:
        bucket = s3.Bucket(config['perftest']['upload_bucket'])

    bucket.wait_until_exists()
    try:
        bucket.Acl().put(ACL='public-read')
    except:
        policy = {
          "Statement":[
                {
                    "Sid":"AddPerm",
                    "Effect":"Allow",
                    "Principal": "*",
                    "Action":["s3:ListBucket"],
                    "Resource":["urn:sgws:s3:::" + config['perftest']['upload_bucket']]
                },
            {
              "Sid":"AddPerm",
              "Effect":"Allow",
              "Principal": "*",
              "Action":["s3:GetObject"],
              "Resource":["urn:sgws:s3:::" + config['perftest']['upload_bucket'] + "/*"]
            }
          ]
        }
        bucket.Policy().put(Policy=json.dumps(policy))



    # Upload the data.
    name = ("%s-%s-%s.csv" % (test_start, test_end, socket.gethostname()))
    s3.meta.client.upload_file('/tmp/histodata', config['perftest']['upload_bucket'], name, ExtraArgs={'ACL': 'public-read', 'ContentType': 'text/csv'})
    s3.meta.client.upload_file('/root/report.html', config['perftest']['upload_bucket'], 'report.html', ExtraArgs={'ACL': 'public-read', 'ContentType': 'text/html'})
    s3.meta.client.upload_file('/root/report.js', config['perftest']['upload_bucket'], 'report.js', ExtraArgs={'ACL': 'public-read', 'ContentType': 'text/javascript'})
    s3.meta.client.upload_file('/root/report.css', config['perftest']['upload_bucket'], 'report.css', ExtraArgs={'ACL': 'public-read', 'ContentType': 'text/css'})


    quit()


############################################################
# Start the script
############################################################
if __name__ == '__main__':
    main()


